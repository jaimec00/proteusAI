# ------------------------------------------------------------------------------

# config file for training proteusAI

# ------------------------------------------------------------------------------

# Path to the YAML config file. defined here for clarity, but need to call this 
# as CL arg for it to work
config: "config/train.yml" 

# ------------------------------------------------------------------------------

# hyperparameters
hyper_parameters:

  # ----------------------------------------------------------------------------

  # main stuff
  d_wf: 256 # d_wf // 2 is the number of wavefunctions defined for each protein, since each wf produces real and imag part
  d_model: 256 # d_model, projects d_wf to this before attention
  num_aa: 20 # number of amino acids

  # ----------------------------------------------------------------------------
  
  # wf embedding params
  embedding:
    min_wl: 3.5
    max_wl: 12
    base_wl: 20.0
    anisotropic: True
    learn_wl: True # learnt the wavenumbers
    learn_aa: True # learn the scaling factors

  # ----------------------------------------------------------------------------

  # wf extraction params
  extraction:
    pre_process:
      d_hidden: 1024
      hidden_layers: -1 # -1 means skip the mlp
    post_process:
      d_hidden: 1024
      hidden_layers: -1
    encoders:
      layers: 4
      heads: 8
      use_bias: True
      learn_spreads: True
      min_rbf: 0.001
      d_hidden_attn: 1024
      hidden_layers_attn: 0

# ------------------------------------------------------------------------------

# training params
training_parameters:

  rng: 0 # for data loading

  single_chain: False # single chain or multichain model, automatically chooses the correct dataset from this, as long as defined below
  ca_only_model: True # Ca only or full backbone model, haven't tested full backbone yet

  epochs: 1000  # number of epochs, training until convergence

  # for pre-training
  weights:
    # only thing to configure is after reach a certain seq sim to freeze the wf embedding weights, 
    # as after get a stable set of values, better to keep it constant for the encoders to learn this representaion,
    # especiallly in mlm, where small changes in aa magnitudes produce big changes in the wf
    embedding: # no freezing
      freeze_at_seq_sim: 100.0 # once validation reaches this, wavenumbers and aa magnitudes are frozen. set to 0 to freeze immediately, >=100 to never freeze
    geo_attn:
      init_bias_off: False # start with no spatial bias, until reach a certain seq sim, which means the features are now useful
      turn_bias_on_at_seq_sim: 100.0

  checkpoint:
    path: ""
    use_model: False
    use_embedding_weights: False
    use_extraction_weights: False
    use_adam: False
    use_scheduler: False
    
  inference:
    temperature: !!float 1e-6
    cycles: 10
  
  # convergence criteria
  early_stopping:
    thresh: 0.00 # delta validation sequence similarity, if below this value, training is stopped. negative values mean the seq sim must decrease before stopping
    tolerance: 30 # how many epochs to consider when calculating delta seq sim for early stopping. takes the max delta seq sim between current epoch and last n epochs, and decides based on this
  
  adam:
    beta1: 0.90  # decay rate of momentum term
    beta2: 0.98  # decay rate of variance term
    epsilon: !!float 10e-9  # for numerical stability in param updates (!!float lets PyYAML know this is a float, not str)
    weight_decay: 0.00 # weight decay, set to 0 for no weightdecay, ie regular adam

  regularization:
    dropout: 0.10  # percentage of dropout
    noise_coords_std: 0.00 # stdev of noise injection into coordinates during training
    use_chain_mask: True # whether to mask all chains except the sequence cluster representative in loss computation, all chains still used for fwd pass as context though

  loss:
    # i think grad accum is v important for diffusion, will see if this helps
    accumulation_steps: 4  # grad accumulation; how many batches to process before learning step. i think mlm needs better grad approx, will see
                            # note that this depends on if doing multi gpu training, if have two gpus with accum=1, then each step occurs after 1 batch per gpu --> 2 batches in this case
    token_based_step: False # false means that accum refers to number of batches processed, true means it refers to the number of valid tokens processed, where valid means the loss is computed for it
    cel:
      label_smoothing: 0.00
    grad_clip_norm: 0.0 # max L2 norm of gradients for gradient clipping. if set to 0, no gradient clipping is applied (not recommended since the loss is a sum)
  
  lr:
    lr_type: "attn"
    lr_step: !!float 1.5e-3 # max lr, ramps up to this val before decreasing  
    warmup_steps: 4000 # number of warmup steps before decreasing
    start_from_step: 0

# ------------------------------------------------------------------------------

# dataset configs
data:

  multi_chain_data_path: "/scratch/hjc2538/projects/proteusAI/data/multi_chain/processed"  # path to data for multi-chain model (dataset from Dapauras et. al.)
  single_chain_data_path: "/scratch/hjc2538/projects/proteusAI/data/single_chain/processed"  # path to data for single chain model (dataset from Ingraham et. al.)

  num_train: -1  # number of training samples to use; -1 means all available
  num_val: -1  # number of validation samples to use; -1 means all available
  num_test: -1  # number of test samples to use; -1 means all available

  # want as few batch_size/seq_length combinations as possible to speed up triton, since it 
  # recompiles the attention kernel for each shape
  # DataHolder class sorts samples by sequence length and splits into max_batch_size batches one time to reduce masking (avoid small seqs being grouped with large seqs), 
  # then recursively randomizes order of samples within batch, splits into two, and continues until batches are <= batch_tokens
  max_batch_size: 256  # maximum samples per batch
  min_seq_size: 16 # minimum sequence length, shorter is padded to this length, this is necessary due to triton matmul, min of 16, but with the option of having larger min
  max_seq_size: 8192 # max sequence lengths, longer samples not included
  batch_tokens: 16384 # number of valid tokens per batch (including non-representative chains, basically the tokens used in computation, not necessarily in loss)
  max_resolution: 3.5 # max_resolution of PDBs

# ------------------------------------------------------------------------------

# Output
output:
  out_path: "/scratch/hjc2538/projects/proteusAI/models/4enc_geoattn_scratch_anisotropicemb_15e4lr"
  model_checkpoints: 10 # number of epochs to save a checkpoint of the model after

# ------------------------------------------------------------------------------

debug:
  # prints each layers gradients after each step so can check for exploding/vanishing gradients
  # note that it is printed before grad clipping
  debug_grad: False # something is wrong with vae and i have no idea what, see what autograd anomoly detector finds

port: 29500 # in case want to run two independant instances of the training on a single machine (one for each gpu), you need different ports for each

# ------------------------------------------------------------------------------

